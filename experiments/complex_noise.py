#!/usr/bin/env python3
"""
Complex Noise Signal Prediction - LSTM Time Series Forecasting

This experiment trains an LSTM on a complex chaotic signal generated by
a logistic map with quasi-periodic forcing. The LSTM learns to predict
the next value in the sequence.

Signal Generation:
    x[t+1] = r * x[t] * (1 - x[t]) + eps * sin(w1 * t) + delta * sin(w2 * t)
    
    Where:
        r = 3.87 (chaotic regime of logistic map)
        eps = 0.05, delta = 0.03 (forcing amplitudes)
        w1 = sqrt(2), w2 = pi/e (incommensurate frequencies)

This creates a challenging prediction task combining:
    - Deterministic chaos (sensitive dependence on initial conditions)
    - Quasi-periodic forcing (irrational frequency ratio prevents exact periodicity)
"""

import sys
import argparse
from pathlib import Path
from typing import Tuple, Optional, List
import numpy as np

# Add src to path for imports - must be before any aquarius_lstm imports
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

# Import torch components directly to avoid tinygrad dependency in __init__
import torch
import torch.nn as nn


def generate_signal(T: int = 1000, x0: float = 0.2) -> np.ndarray:
    """
    Generate chaotic logistic map signal with quasi-periodic forcing.
    
    Args:
        T: Number of timesteps to generate
        x0: Initial condition
        
    Returns:
        Signal array of shape (T,) with values in [0, 1]
    """
    r = 3.87
    eps = 0.05
    delta = 0.03
    w1 = np.sqrt(2.0)
    w2 = np.pi / np.e

    x = np.zeros(T)
    x[0] = x0

    for t in range(T - 1):
        forcing = eps * np.sin(w1 * t) + delta * np.sin(w2 * t)
        x_next = r * x[t] * (1 - x[t]) + forcing

        # clip to [0, 1] so the system does not blow up
        x[t + 1] = np.clip(x_next, 0.0, 1.0)

    return x


def create_sequences(
    signal: np.ndarray,
    seq_len: int = 50,
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Create overlapping sequences for next-step prediction.
    
    Args:
        signal: 1D signal array
        seq_len: Length of each input sequence
        
    Returns:
        X: Input sequences of shape (num_samples, seq_len, 1)
        Y: Target values of shape (num_samples, 1)
    """
    X, Y = [], []
    for i in range(len(signal) - seq_len):
        X.append(signal[i:i + seq_len])
        Y.append(signal[i + seq_len])
    
    X = np.array(X, dtype=np.float32).reshape(-1, seq_len, 1)
    Y = np.array(Y, dtype=np.float32).reshape(-1, 1)
    
    return X, Y


def run_torch(
    signal_length: int = 2000,
    seq_len: int = 50,
    hidden_size: int = 32,
    num_epochs: int = 100,
    batch_size: int = 32,
    learning_rate: float = 0.001,
    seed: Optional[int] = 42,
    log_every: int = 10,
    plot: bool = True,
) -> Tuple[List[float], np.ndarray, np.ndarray]:
    """
    Train LSTM on complex noise signal using PyTorch.
    
    Returns:
        losses: Training loss history
        y_true: Ground truth signal for plotting
        y_pred: Predicted signal for plotting
    """
    from aquarius_lstm.cell_torch import LSTMCell1997WithForgetGate
    
    print(f"\n{'='*60}")
    print("COMPLEX NOISE SIGNAL PREDICTION - PyTorch LSTM")
    print(f"{'='*60}")
    print(f"Signal length: {signal_length}")
    print(f"Sequence length: {seq_len}")
    print(f"Hidden size: {hidden_size}")
    print(f"Batch size: {batch_size}")
    print(f"Learning rate: {learning_rate}")
    print(f"{'='*60}\n")
    
    if seed is not None:
        torch.manual_seed(seed)
        np.random.seed(seed)
    
    # Generate signal and create sequences
    signal = generate_signal(T=signal_length, x0=0.2)
    X, Y = create_sequences(signal, seq_len=seq_len)
    
    # Train/test split (80/20)
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    Y_train, Y_test = Y[:split_idx], Y[split_idx:]
    
    print(f"Training samples: {len(X_train)}")
    print(f"Test samples: {len(X_test)}")
    
    # Convert to tensors
    X_train_t = torch.tensor(X_train)
    Y_train_t = torch.tensor(Y_train)
    X_test_t = torch.tensor(X_test)
    Y_test_t = torch.tensor(Y_test)
    
    # Build model
    cell = LSTMCell1997WithForgetGate(
        input_size=1,
        hidden_size=hidden_size,
        input_gate_bias=0.0,
        forget_gate_bias=1.0,
        seed=seed,
    )
    linear = nn.Linear(hidden_size, 1)
    
    params = list(cell.parameters()) + list(linear.parameters())
    optimizer = torch.optim.Adam(params, lr=learning_rate)
    criterion = nn.MSELoss()
    
    # Training loop
    losses = []
    num_batches = len(X_train) // batch_size
    
    for epoch in range(num_epochs):
        epoch_loss = 0.0
        
        # Shuffle training data
        perm = np.random.permutation(len(X_train))
        X_train_shuffled = X_train_t[perm]
        Y_train_shuffled = Y_train_t[perm]
        
        for batch_idx in range(num_batches):
            start = batch_idx * batch_size
            end = start + batch_size
            
            X_batch = X_train_shuffled[start:end]  # (batch, seq_len, 1)
            Y_batch = Y_train_shuffled[start:end]  # (batch, 1)
            
            optimizer.zero_grad()
            
            # Initialize hidden state
            h, s_c = cell.init_state(batch_size=batch_size)
            
            # Forward through sequence (seq_len, batch, input_size)
            X_seq = X_batch.permute(1, 0, 2)  # (seq_len, batch, 1)
            for t in range(seq_len):
                h, s_c = cell(X_seq[t], h, s_c)
            
            # Predict
            pred = linear(h)
            loss = criterion(pred, Y_batch)
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(params, max_norm=1.0)
            optimizer.step()
            
            epoch_loss += loss.item()
        
        avg_loss = epoch_loss / num_batches
        losses.append(avg_loss)
        
        if (epoch + 1) % log_every == 0:
            print(f"Epoch {epoch+1:3d}/{num_epochs}: Loss = {avg_loss:.6f}")
    
    # Evaluate on test set
    print("\nEvaluating on test set...")
    predictions = []
    
    with torch.no_grad():
        # Process test set in batches
        test_batches = (len(X_test) + batch_size - 1) // batch_size
        
        for batch_idx in range(test_batches):
            start = batch_idx * batch_size
            end = min(start + batch_size, len(X_test))
            actual_batch_size = end - start
            
            X_batch = X_test_t[start:end]
            
            h, s_c = cell.init_state(batch_size=actual_batch_size)
            
            X_seq = X_batch.permute(1, 0, 2)
            for t in range(seq_len):
                h, s_c = cell(X_seq[t], h, s_c)
            
            pred = linear(h)
            predictions.append(pred.numpy())
    
    y_pred = np.concatenate(predictions, axis=0)
    y_true = Y_test
    
    # Calculate metrics
    mse = np.mean((y_pred - y_true) ** 2)
    mae = np.mean(np.abs(y_pred - y_true))
    
    print(f"\nTest Results:")
    print(f"  MSE: {mse:.6f}")
    print(f"  MAE: {mae:.6f}")
    
    if plot:
        plot_results(losses, y_true, y_pred, signal, seq_len, split_idx)
    
    return losses, y_true, y_pred


def plot_results(
    losses: List[float],
    y_true: np.ndarray,
    y_pred: np.ndarray,
    signal: np.ndarray,
    seq_len: int,
    split_idx: int,
) -> None:
    """
    Plot training loss curve and prediction comparison.
    """
    import matplotlib.pyplot as plt
    
    fig, axes = plt.subplots(2, 1, figsize=(14, 10))
    
    # Loss curve
    ax1 = axes[0]
    ax1.plot(losses, color='#2E86AB', linewidth=2)
    ax1.set_xlabel('Epoch', fontsize=12)
    ax1.set_ylabel('MSE Loss', fontsize=12)
    ax1.set_title('Training Loss Curve', fontsize=14, fontweight='bold')
    ax1.set_yscale('log')
    ax1.grid(True, alpha=0.3)
    ax1.set_facecolor('#F8F9FA')
    
    # Signal comparison
    ax2 = axes[1]
    
    # Plot full signal as context (faded)
    time_full = np.arange(len(signal))
    ax2.plot(time_full, signal, color='#CCCCCC', linewidth=0.5, label='Full Signal', alpha=0.5)
    
    # Plot test region: true vs predicted
    test_start = split_idx + seq_len
    time_test = np.arange(test_start, test_start + len(y_true))
    
    ax2.plot(time_test, y_true.flatten(), color='#2E86AB', linewidth=1.5, 
             label='True Signal', alpha=0.8)
    ax2.plot(time_test, y_pred.flatten(), color='#E94F37', linewidth=1.5, 
             label='LSTM Prediction', linestyle='--', alpha=0.8)
    
    # Highlight test region
    ax2.axvline(x=test_start, color='#28A745', linestyle=':', linewidth=2, 
                label='Test Region Start')
    
    ax2.set_xlabel('Time Step', fontsize=12)
    ax2.set_ylabel('Signal Value', fontsize=12)
    ax2.set_title('Complex Noise Signal: True vs LSTM Prediction', fontsize=14, fontweight='bold')
    ax2.legend(loc='upper right', fontsize=10)
    ax2.grid(True, alpha=0.3)
    ax2.set_facecolor('#F8F9FA')
    
    plt.tight_layout()
    
    # Save figure
    output_path = Path(__file__).parent.parent / "assets" / "complex_noise_results.png"
    output_path.parent.mkdir(exist_ok=True)
    plt.savefig(output_path, dpi=150, bbox_inches='tight', facecolor='white')
    print(f"\nPlot saved to: {output_path}")
    
    plt.show()


def main():
    parser = argparse.ArgumentParser(description="Complex Noise Signal Prediction with LSTM")
    parser.add_argument("--signal-length", type=int, default=2000,
                        help="Length of generated signal")
    parser.add_argument("--seq-len", type=int, default=50,
                        help="Input sequence length for LSTM")
    parser.add_argument("--hidden-size", type=int, default=32,
                        help="LSTM hidden state size")
    parser.add_argument("--epochs", type=int, default=100,
                        help="Number of training epochs")
    parser.add_argument("--batch-size", type=int, default=32,
                        help="Training batch size")
    parser.add_argument("--lr", type=float, default=0.001,
                        help="Learning rate")
    parser.add_argument("--seed", type=int, default=42,
                        help="Random seed")
    parser.add_argument("--no-plot", action="store_true",
                        help="Disable plotting")
    args = parser.parse_args()
    
    run_torch(
        signal_length=args.signal_length,
        seq_len=args.seq_len,
        hidden_size=args.hidden_size,
        num_epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.lr,
        seed=args.seed,
        plot=not args.no_plot,
    )


if __name__ == "__main__":
    main()
